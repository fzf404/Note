(window.webpackJsonp=window.webpackJsonp||[]).push([[38],{666:function(n,t){n.exports="\x3c!--\ntitle: 10-Pytorch入门\nsort:\n--\x3e\n\n> 使用 pytorch\n>\n> [官方安装教程](https://pytorch.org/get-started/locally/)\n\n### 测试\n\n```python\n$ python3\n>>> import torch\n>>> print(torch.rand(5,3))\ntensor([[0.4404, 0.8982, 0.5171],\n        [0.8257, 0.1787, 0.0903],\n        [0.5172, 0.6681, 0.8938],\n        [0.0109, 0.2770, 0.5885],\n        [0.0446, 0.9772, 0.1019]])\n>>> torch.cuda.is_available()\nTrue\n```\n\n## 数据操作\n\n> 关键词说明\n\n`tensor`: 多维数组\n\n> 建立数据\n\n```python\ntorch.tensor([1,2,1])\t\t# tensor([1, 2, 1])\ntorch.Tensor(2,3)\t\t\t\t# torch.Size([2, 3])\ntorch.FloatTensor(2)\t\t# 随机两个tensor\ntorch.from_numpy(data)\t# numpy转torch\n\ntorch.empty(5,3)\ntorch.rand(5,3)\t\t\t# 范围(0, 1)\ntorch.randn(5, 3)\t\t# 范围(-1, 1)\ntorch.arange(0,10,2)\t\t# tensor([0,2,4,6,8])\n\ntorch.linspace(0,10,steps=4)\t# tensor([0.00,3.33,6.67,10.00])\ntorch.logspace(0,-1,steps=4)\t# tensor([1.0000, 0.4642, 0.2154, 0.1000])\ntorch.eye(5,5)\n'''\ntensor([[1., 0., 0., 0., 0.],\n        [0., 1., 0., 0., 0.],\n        [0., 0., 1., 0., 0.],\n        [0., 0., 0., 1., 0.],\n        [0., 0., 0., 0., 1.]])\n'''\n\ntorch.zeros(5,3).type()\t# torch.FloatTensor\ntorch.zeros(5,3,dtype=torch.long)\ntorch.ones(5,3)\n\nx = torch.tensor([1,2])\nx = x.new_ones(5,3,dtype=torch.double)\n'''\ntensor([[1., 1., 1.],\n        [1., 1., 1.],\n        [1., 1., 1.],\n        [1., 1., 1.],\n        [1., 1., 1.]], dtype=torch.float64)\n'''\n# 仿照x填入数据\nx = torch.randn_like(x, dtype=torch.float)\n'''\ntensor([[ 1.2358,  0.8365, -0.3136],\n        [-1.7273,  1.6472,  0.0520],\n        [-0.5576, -0.6262, -0.5728],\n        [-0.2788, -0.0570, -0.0740],\n        [-0.0728,  0.2494,  0.9421]])\n'''\n# 数据信息\nx.size()\nx.size(0)\t\t# 行数\nx.size(1)\t\t# 列数\n```\n\n> 操作数据\n\n```python\ny.add_(x)\ntorch.add(x, y, out=result)\n\n# 查看\ny.view(-1,5)\t# 规定形状查看，不限行数 每行5个元素\ny[3,1].item()\t# 取值\n\n# 打乱保持索引\na = torch.rand(4,6)\nb = torch.rand(4,4)\n# 随机索引\nidx = torch.randperm(4)\n# 打乱\na[idx]\nb[idx]\n\n# 取值\na = torch.randn(4,3,28,28)\na[:,1,...].shape\ntorch.size([4,28,28])\n# 取值列号，取值行号\na.index_select(0,torch.tensor([0,1])).shape\ntorch.where(cond>0.5,a,b)\t\t# cond>0.5则取a\n\n# 掩码取值\nx = torch.randn(3,4)\nmask = x.ge(0.5)\nx.masked_select(mask)\n\n# 维度操作\na.squeeze(1).shape\t\t# 挤压维度\na.unsqueeze(1).shape\t# 增加维度\na.expand([4,32,28,28])\t# 扩展维度\na.expand([4,32,28,28])\t# 重复扩展维度-次数\n# 转至\na.t() # 维度调转2D\na.a.transpose(1,3)\t# 1-3维度调转\na.permute(2,3,1,0)\t# 维度转换\n\n# 合并拆分\na = torch.rand(4,32,8)\nb = torch.rand(4,32,8)\ntorch.cat([a,b],dim=0)\t\t# torch.Size([8, 32, 8])\nc = torch.stack([a,b],dim=1)\t# torch.Size([4, 2, 32, 8])\naa,b = c.split(1,dim=1)\t\t# [4, 1, 32, 8]\n\n# 相等\t\t大于\na.eq(a,b) gt(0)\n```\n\n### CUDA\n\n```python\n# True\ntorch.cuda.is_available()\n# Use .to() move tensor to other device\ndevice_obj = torch.device('cuda')\nx = torch.rand(5,3)\nx.to(device_obj)\n'''\ntensor([[0.4783, 0.3188, 0.4842],\n        [0.2552, 0.4863, 0.7803],\n        [0.1680, 0.7451, 0.6912],\n        [0.9617, 0.3069, 0.7458],\n        [0.7645, 0.9438, 0.0892]], device='cuda:0')\n'''\nx.to('cpu', dtype=torch.double)\n'''\ntensor([[0.4783, 0.3188, 0.4842],\n        [0.2552, 0.4863, 0.7803],\n        [0.1680, 0.7451, 0.6912],\n        [0.9617, 0.3069, 0.7458],\n        [0.7645, 0.9438, 0.0892]], dtype=torch.float64)\n'''\n```\n\n## 数学计算\n\n```python\n# 相加\ntorch.add(x, y, out=result)\n# 相乘相除\ntorch.mul(x, y, out=result)\ntorch.div(x, y, out=result)\n# 矩阵相乘\ntorch.matmul(a,b)\ntorch.mm(a,b)\t\t\t# 2维简写\na@b\t\t\t\t\t\t\t\t# 简写\n\n# 平方与平方根\na.pow(2)\na.sqrt()\na.rsqrt()\t\t# 平方根倒数\n\n# 对数 e^x\na = torch.exp(torch.ones(2,2))\na.log()\t\t# 取对数\n\n# 值\na = torch.tensor(3.14)\na.floor(),a.ceil(),a.trunc(),a.frac(),a.round()\n# (tensor(3.), tensor(4.), tensor(3.), tensor(0.1400)), tensor(3.)\n# 设置最大最小值\na.clamp(10)\t\t# 最大值\na.clamp(1,10)\t# 1-10之间\n# 最小\t最大\t平均\t\t累乘\t\t求和\na.min() max() mean() prod()\tsum()\na.argmax() argmin()\t\t# 最大最小值的索引\n# 取最大值及其对应的索引 取前三3个\ngrad.topk(3,dim=1)\ngrad.topk(3,dim=1,largest=False)\t# 最小\ngard.kthvalue(4)\t# 第四大的值\n\n# 求导\nx = torch.tensor(2.)\t# 定义求导\na = torch.tensor(1., requires_grad=True)\nb = torch.tensor(2., requires_grad=True)\nc = torch.tensor(5., requires_grad=True)\ny = a**2*x + b*x + c\ngrads = torch.autograd.grad(y,[a,b,c])\ngrads[0],grads[1],gard[2]\n\n# 范数 -> 平方和开方\n# 1范数平方求和\na.norm(1)\n# 2范数平方求和开根\na.norm(2, dim=1)\n```\n"}}]);