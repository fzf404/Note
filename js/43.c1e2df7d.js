(window.webpackJsonp=window.webpackJsonp||[]).push([[43],{671:function(n,e){n.exports="\x3c!--\ntitle: 15-RNN\nsort:\n--\x3e\n\n> 循环神经网络\n\n- 数据处理方式\n\n> 3 句话，每句 10 词，每词 100 维向量\n>\n> `seq_len=10 batch=3 feature_len=100`\n\n- 隐藏记忆单元\n\n> h 是可自定义的二维向量 `[batch,hidden_len]`\n>\n> 每个样本用 `hidden_len` 长度的向量记录\n\n### 构造 RNN\n\n```python\nfrom torch import nn\n\n# 表示feature_len=100, hidden_len=10(隐藏单元)\nrnn = nn.RNN(100, 10)\n# odict_keys(['weight_ih_l0', 'weight_hh_l0', 'bias_ih_l0', 'bias_hh_l0'])\n# 源数据与隐藏数据的参数w，源数据与隐藏数据的偏执b\nprint(rnn._parameters.keys())\n```\n\n## 实战\n\n```python\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\nfrom torch import optim\n\n# 设置数据参数\nnum_time_steps = 50   # 输入数据长度\ninput_size = 1      # 大小\nhidden_size = 16    # 隐藏数据大小\noutput_size = 1     # 输出大小\nlr = 0.01\niterations = 6000    # 训练次数\n\n\nclass RnnNet(nn.Module):\n  def __init__(self):\n    super(RnnNet,self).__init__()\n    self.rnn = nn.RNN(\n      input_size = input_size,\n      hidden_size = hidden_size,\n      num_layers = 1,\n      # batch放在最前面\n      batch_first = True,\n    )\n    # 输入维度hidden_size*output_size,输出维度output_size的线性层\n    self.linear = nn.Linear(hidden_size,output_size)\n\n  def forward(self,x,hidden_prev):\n    out,hidden_prev = self.rnn(x,hidden_prev)\n    out = out.view(-1,hidden_size)\n    out = self.linear(out)\n    out = out.unsqueeze(dim = 0)\n    return out,hidden_prev\n\n\ndevice = torch.device('cuda:0')\nmodel = RnnNet()      # 初始化模型\ncriterion = nn.MSELoss()  # 均方误差\n# Adam优化算法\noptimizer = optim.Adam(model.parameters(),lr = lr)\n# 隐藏层\nhidden_prev = torch.zeros(1,1,hidden_size)\n# 训练\nfor iter in range(iterations):\n    # 随机 0-2 的起始点\n    start = np.random.randint(3,size = 1)[0]\n    # 生成从start->start+10区间内共计num_time_steps个点\n    time_steps = np.linspace(start,start + 10,num_time_steps)\n    data = np.sin(time_steps)\n    data = data.reshape(num_time_steps,1)\n    x = torch.tensor(data[:-1]).float().view(1,num_time_steps - 1,1)\n    y = torch.tensor(data[1:]).float().view(1,num_time_steps - 1,1)\n    # 进行预测\n    output,hidden_prev = model(x,hidden_prev)\n    hidden_prev = hidden_prev.detach()\n    # 计算损失值\n    loss = criterion(output,y)\n    model.zero_grad()\n    loss.backward()\n\n    optimizer.step()\n\n    if iter % 1000 == 999:\n        print(f\"Iteration: {iter+1} loss: {loss.item()}\")\n\n\npredictions = []\n# 取第一个预测值\ninput =  x[:,0,:]\nfor _ in range(x.shape[1]):\n    input = input.view(1,1,1)\n    # 预测下一位置\n    (pred,hidden_prev) = model(input,hidden_prev)\n    input = pred\n    predictions.append(pred.detach().numpy().ravel()[0])\n\n# 绘图\nx = x.data.numpy().ravel()\ny = y.data.numpy()\nplt.scatter(time_steps[:-1], x.ravel(), s=90)\nplt.plot(time_steps[:-1], x.ravel())\n\nplt.scatter(time_steps[1:], predictions)\nplt.show()\n```\n"}}]);